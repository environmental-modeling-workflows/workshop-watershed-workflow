{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68c4f8ea",
   "metadata": {
    "papermill": {
     "duration": 0.136685,
     "end_time": "2022-03-22T21:32:19.613337",
     "exception": false,
     "start_time": "2022-03-22T21:32:19.476652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Example: Mixed-Element Mesh for Delineated Watershed\n",
    "\n",
    "This workflow provides a part of worlflow to develop an streamaligned mixed-element mesh for Taylor upstream watershed. Long quad elements with pentagons at junctions are placed along NHDPlus flowlines to represent rivers/streams. Rest of the domain is meshed with standard TIN. This example has internal huc boundaries that are modified to accomodate river corridor. This workflow only shows steps to get a terrain following 2D surface mesh. Rest of the steps are same as other examples\n",
    "\n",
    "It uses the following datasets:\n",
    "\n",
    "* `NHD Plus` for the watershed boundary and hydrography.\n",
    "* `NED` for elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ef30b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing all the package needed to run teh watershed workflow\n",
    "# conda package imports\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import logging\n",
    "import pandas as pd\n",
    "import copy\n",
    "import shapely\n",
    "\n",
    "import watershed_workflow\n",
    "import watershed_workflow.source_list\n",
    "import watershed_workflow.ui\n",
    "import watershed_workflow.utils\n",
    "import watershed_workflow.plot\n",
    "import watershed_workflow.mesh\n",
    "import watershed_workflow.regions\n",
    "import watershed_workflow.densification\n",
    "import watershed_workflow.condition\n",
    "watershed_workflow.ui.setup_logging(1,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1529dce-8055-40fc-ad06-b648057f51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# silence shapely2.0 and crs WKT warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd98b139",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T21:32:20.180640Z",
     "iopub.status.busy": "2022-03-22T21:32:20.180113Z",
     "iopub.status.idle": "2022-03-22T21:32:20.196203Z",
     "shell.execute_reply": "2022-03-22T21:32:20.196537Z"
    },
    "papermill": {
     "duration": 0.153266,
     "end_time": "2022-03-22T21:32:20.196694",
     "exception": false,
     "start_time": "2022-03-22T21:32:20.043428",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters cell -- this provides all parameters that can be changed via pipelining to generate a new watershed.\n",
    "name = 'Taylor_Upstream' # name the domain, used in filenames, etc\n",
    "hucs = ['140200010101','140200010102','140200010103'] # a list of HUCs to run\n",
    "huc_level = 12 # if provided, an int setting the level at which to include HUC boundaries\n",
    "modis_name = None\n",
    "\n",
    "# geometric parameters\n",
    "simplify = 100 # length scale to target average edge\n",
    "simplify_rivers = 100\n",
    "stream_outlet_width = 500 # half-width to track a labeled set on which to get discharge\n",
    "ignore_small_rivers = 2 # ignore rivers which have this or fewer reaches.  likely they are irrigation ditches\n",
    "                        # or other small features which make things complicated but likely don't add much value\n",
    "prune_by_area_fraction = 0.02 # ignore reaches whose accumulated catchment area is less than this fraction of the\n",
    "                              # full domain's area\n",
    "prune_by_area_fraction_waterbodies = None\n",
    "num_smoothing_sweeps = 5 # number of times to smooth the DEM prior to elevating\n",
    "\n",
    "# simulation control\n",
    "start_year = 1980  # year to start and end simulation simulation -- note these start and end Oct 1 of the year\n",
    "end_year = 2020\n",
    "min_porosity = 0.05 # minimum porosity considered too small\n",
    "max_permeability = 1.e-10 # max value allowed for permeability\n",
    "max_vg_alpha = 1.e-3 # max value of van Genuchten's alpha -- our correlation is not valid for some soils\n",
    "\n",
    "# triangle refinement control\n",
    "include_rivers = True\n",
    "refine_d0 = 100\n",
    "refine_d1 = 500\n",
    "refine_A0 = 8000\n",
    "refine_A1 = 50000\n",
    "\n",
    "# soil structure\n",
    "use_geologic_layer = True\n",
    "\n",
    "# logistics\n",
    "generate_plots = True # plots take time to make and aren't always needed\n",
    "generate_daymet = True # potentially don't do Met data forcing\n",
    "generate_modis = True\n",
    "\n",
    "include_heterogeneous = True\n",
    "include_homogeneous = False # if true, also write files for homogeneous runs\n",
    "include_homogeneous_wrm = False # if true, also write files for homogeneous WRMs\n",
    "include_homogeneous_wrm_porosity = False # if true, also write files for homogeneous porosity and WRMs\n",
    "include_homogeneous_wrm_permeability = False # if true, also write files for homogeneous perm and WRMs\n",
    "\n",
    "log_to_file = False  # if true, write to file instead of in the notebook output\n",
    "figsize = (6,6)\n",
    "figsize_3d = (8,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c39048e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T21:32:20.749518Z",
     "iopub.status.busy": "2022-03-22T21:32:20.749013Z",
     "iopub.status.idle": "2022-03-22T21:32:20.764582Z",
     "shell.execute_reply": "2022-03-22T21:32:20.764929Z"
    },
    "papermill": {
     "duration": 0.154735,
     "end_time": "2022-03-22T21:32:20.765091",
     "exception": false,
     "start_time": "2022-03-22T21:32:20.610356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameter checking\n",
    "assert(simplify > 0 and simplify < 300)\n",
    "assert(ignore_small_rivers == None or (ignore_small_rivers >= 0 and ignore_small_rivers <= 100))\n",
    "assert(prune_by_area_fraction == None or (prune_by_area_fraction >= 0 and prune_by_area_fraction < 1))\n",
    "assert(start_year >= 1980 and start_year < 2020)\n",
    "\n",
    "if type(hucs) is str:\n",
    "    assert(hucs[0] == '[')\n",
    "    assert(hucs[-1] == ']')\n",
    "    hucs = hucs[1:-1]\n",
    "    hucs = hucs.split(',')\n",
    "    hucs = [h.strip() for h in hucs]\n",
    "    if hucs[-1] == '':\n",
    "        hucs = hucs[:-1]\n",
    "\n",
    "if huc_level is None:\n",
    "    huc_level = len(hucs[0])\n",
    "else:\n",
    "    assert(huc_level >= len(hucs[0]))\n",
    "huc_key = f'HUC{huc_level}'\n",
    "\n",
    "if prune_by_area_fraction_waterbodies is None:\n",
    "    prune_by_area_fraction_waterbodies = prune_by_area_fraction * 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9695d127",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T21:32:21.031619Z",
     "iopub.status.busy": "2022-03-22T21:32:21.031096Z",
     "iopub.status.idle": "2022-03-22T21:32:21.045417Z",
     "shell.execute_reply": "2022-03-22T21:32:21.045762Z"
    },
    "papermill": {
     "duration": 0.151242,
     "end_time": "2022-03-22T21:32:21.045921",
     "exception": false,
     "start_time": "2022-03-22T21:32:20.894679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a dictionary of outputs -- will include all filenames generated\n",
    "outputs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93821426",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T21:32:23.859292Z",
     "iopub.status.busy": "2022-03-22T21:32:23.858704Z",
     "iopub.status.idle": "2022-03-22T21:32:23.891784Z",
     "shell.execute_reply": "2022-03-22T21:32:23.892127Z"
    },
    "papermill": {
     "duration": 0.173444,
     "end_time": "2022-03-22T21:32:23.892314",
     "exception": false,
     "start_time": "2022-03-22T21:32:23.718870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note that, by default, we tend to work in the DayMet CRS because this allows us to avoid\n",
    "# reprojecting meteorological forcing datasets.\n",
    "crs = watershed_workflow.crs.daymet_crs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6569dcd",
   "metadata": {
    "papermill": {
     "duration": 0.138411,
     "end_time": "2022-03-22T21:32:24.168402",
     "exception": false,
     "start_time": "2022-03-22T21:32:24.029991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sources and setup\n",
    "\n",
    "Next we set up the source watershed and coordinate system and all data sources for our mesh.  We will use the CRS that is included in the shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ffc4f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T21:32:24.441366Z",
     "iopub.status.busy": "2022-03-22T21:32:24.440867Z",
     "iopub.status.idle": "2022-03-22T21:32:24.473004Z",
     "shell.execute_reply": "2022-03-22T21:32:24.473532Z"
    },
    "papermill": {
     "duration": 0.171121,
     "end_time": "2022-03-22T21:32:24.473705",
     "exception": false,
     "start_time": "2022-03-22T21:32:24.302584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.info(\"\")\n",
    "logging.info(f\"Meshing shape: {hucs}\")\n",
    "logging.info(\"=\"*30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448bb7ea",
   "metadata": {
    "papermill": {
     "duration": 0.184957,
     "end_time": "2022-03-22T21:32:24.790846",
     "exception": false,
     "start_time": "2022-03-22T21:32:24.605889",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A wide range of data sources are available; here we use the defaults except for using NHD Plus for watershed boundaries and hydrography (the default is NHD, which is lower resolution and therefore smaller download sizes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17feb6e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T21:32:25.075478Z",
     "iopub.status.busy": "2022-03-22T21:32:25.074980Z",
     "iopub.status.idle": "2022-03-22T21:32:25.113081Z",
     "shell.execute_reply": "2022-03-22T21:32:25.109830Z"
    },
    "papermill": {
     "duration": 0.178218,
     "end_time": "2022-03-22T21:32:25.113230",
     "exception": false,
     "start_time": "2022-03-22T21:32:24.935012",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up a dictionary of source objects\n",
    "sources = watershed_workflow.source_list.get_default_sources()\n",
    "sources['hydrography'] = watershed_workflow.source_list.hydrography_sources['NHD Plus']\n",
    "sources['HUC'] = watershed_workflow.source_list.huc_sources['NHD Plus']\n",
    "sources['DEM'] = watershed_workflow.source_list.dem_sources['NED 1/3 arc-second']\n",
    "watershed_workflow.source_list.log_sources(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc8052",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T21:32:25.394969Z",
     "iopub.status.busy": "2022-03-22T21:32:25.394455Z",
     "iopub.status.idle": "2022-03-22T21:32:26.365219Z",
     "shell.execute_reply": "2022-03-22T21:32:26.365559Z"
    },
    "papermill": {
     "duration": 1.114087,
     "end_time": "2022-03-22T21:32:26.365716",
     "exception": false,
     "start_time": "2022-03-22T21:32:25.251629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # load the huc\n",
    "# my_hucs = []\n",
    "# for huc in hucs:\n",
    "#     _, ws = watershed_workflow.get_hucs(sources['HUC'], huc, huc_level, crs)\n",
    "#     my_hucs.extend(ws)\n",
    "\n",
    "# watershed = watershed_workflow.split_hucs.SplitHUCs(my_hucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf9cb0b",
   "metadata": {
    "papermill": {
     "duration": 0.175642,
     "end_time": "2022-03-22T21:32:26.710144",
     "exception": false,
     "start_time": "2022-03-22T21:32:26.534502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generate the surface mesh\n",
    "\n",
    "First we'll generate the flattened, 2D triangulation, which builds on hydrography data.  Then we download a digital elevation map from the National Elevation Dataset, and extrude that 2D triangulation to a 3D surface mesh based on interpolation between pixels of the DEM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c64ab13",
   "metadata": {
    "papermill": {
     "duration": 0.161358,
     "end_time": "2022-03-22T21:32:27.040288",
     "exception": false,
     "start_time": "2022-03-22T21:32:26.878930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Get river network\n",
    "\n",
    "This will download the river network from the NHD Plus database, and simplify the network, constructing a tree-like data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93074252",
   "metadata": {},
   "source": [
    "While constructing river, user should be intetntional with prune options to get desired river network density. It is recommended to not have too dense river network if not needed as each reach in the river tree will show up in quad mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aedd2c",
   "metadata": {},
   "source": [
    "This watershed has three subwatersheds. The internal watershed boundaries will be accomodated in the river mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ee68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pickle files of already created rivers\n",
    "import pickle\n",
    "with open(\"./data/pickled_data/taylor_upstream_rivers\", 'rb') as handle:\n",
    "    rivers = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88522010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pickle files of already created rivers\n",
    "import pickle\n",
    "with open(\"./data/pickled_data/taylor_upstream_rivers_watershed\", 'rb') as handle:\n",
    "    watershed = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c321e6-7361-4a40-b996-f87fcf0f7a45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T21:32:46.413175Z",
     "iopub.status.busy": "2022-03-22T21:32:46.412625Z",
     "iopub.status.idle": "2022-03-22T21:32:46.919158Z",
     "shell.execute_reply": "2022-03-22T21:32:46.919637Z"
    },
    "papermill": {
     "duration": 1.276371,
     "end_time": "2022-03-22T21:32:46.919877",
     "exception": false,
     "start_time": "2022-03-22T21:32:45.643506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if generate_plots:\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = watershed_workflow.plot.get_ax(crs, fig, window=[0.05,0.1,0.9,0.8])\n",
    "    watershed_workflow.plot.hucs(watershed, crs, 'k', ax)\n",
    "    watershed_workflow.plot.rivers(rivers, crs, 'b', ax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0350c9",
   "metadata": {},
   "source": [
    "In the simplification step below, we keep the original river so that we can sample vertices from these original dense rivers and huc boundaries to get vertex density at desired resolution.\n",
    "\n",
    "Using the Douglas-Peucker algorithm, we simplify the flowline by removing non-essential vertices with shapely's \"simplify\" method, ensuring accurate representation. Additional simplifications, such as merging minor reaches and aligning watershed boundaries with flowlines, are also performed. \n",
    "\n",
    "TIPS:\n",
    "- keep merge tolerance about 70% of the simplify_rivers tolerance\n",
    "- use smaller snap tolerance (50% of simplify_rivers) if non-outlet reaches start snapping to the watershed boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca77af07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# keeping the originals\n",
    "rivers_orig=[river.deepcopy() for river in rivers]\n",
    "watershed_orig=copy.deepcopy(watershed)\n",
    "\n",
    "# simplifying\n",
    "rivers = watershed_workflow.simplify(watershed, rivers, simplify_hucs=150, simplify_rivers=80, snap_tol = 30, merge_tol=50, cut_intersections=True)\n",
    "\n",
    "# for plotting purpose only\n",
    "rivers_simplified=[river.deepcopy() for river in rivers]\n",
    "watershed_simplified=copy.deepcopy(watershed)\n",
    "\n",
    "print('number of reaches in original', len(rivers_orig[0]), 'number of reaches in simplified', len(rivers[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d447b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "watershed_workflow.ui.setup_logging(1,None)\n",
    "\n",
    "fig, axs = plt.subplots(1,2,subplot_kw={'projection':watershed_workflow.crs.to_cartopy(crs)})\n",
    "watershed_workflow.plot.hucs(watershed_orig, crs, 'k', axs[0])\n",
    "axs[0].set_title('original river network and hucs',fontsize=16)\n",
    "watershed_workflow.plot.hucs(watershed, crs, 'k', axs[1])\n",
    "axs[1].set_title('after simplify and prune',fontsize=16)\n",
    "\n",
    "for river in rivers_orig:\n",
    "\n",
    "    for node in river.preOrder():\n",
    "        x,y=node.segment.xy\n",
    "        axs[0].plot(x,y,'-o',markersize=2)\n",
    "\n",
    "for river in rivers_simplified:\n",
    "    for node in river.preOrder():\n",
    "        x,y=node.segment.xy\n",
    "        axs[1].plot(x,y,'-o',markersize=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931cbac0",
   "metadata": {},
   "source": [
    "In step two, we enhance the flowline's resolution by adding nearly uniformly distributed vertices, sampled from the original to regain any curvature lost during simplification, with an upper user-defined limit dictating the distance between consecutive vertices, ultimately determining the quad length in the river mesh. When the distance in a reach segment, represented as a shapely.LineString object, surpasses this scale, additional vertices are inserted, their number and coordinates derived using 1D interpolation from the original segment vertices. \n",
    "\n",
    "The limit of distance between vertices on the huc boundary is a function of distance from the river. Parts of huc segments close to river get vertices placd at higher density. \n",
    "\n",
    "Sharp bends in the river and tributaries running closely before merging are a couple of cases that can constrain triangulation to yield small triangles. Hence, we smoothen out some of these sharp angles\n",
    "\n",
    "TIPS:\n",
    "\n",
    "- provide L0 about same as length scale limit on river and  L1 about 1.5 to 2 times times length scale limit on river\n",
    "- profile d1 atleast equal to length scale limit on river"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477944f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = 20; d1 = 100\n",
    "L0 = 100; L1 = 250\n",
    "\n",
    "# densify_watershed\n",
    "watershed_workflow.densification.densify_hucs(watershed, watershed_orig, rivers, limit_scales=[d0,L0,d1,L1])\n",
    "\n",
    "#densify_river\n",
    "watershed_workflow.densification.densify_rivers(rivers, rivers_orig, limit=120)\n",
    "\n",
    "# treat sharp angles\n",
    "watershed_workflow.densification.remove_sharp_angles(rivers, watershed, angle_limit=30, junction_angle_limit=20, huc_seg_river_angle_limit=25, limit=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d3b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting results\n",
    "plt.rcParams['figure.figsize'] = [20, 12]\n",
    "\n",
    "fig, axs = plt.subplots(1,3,subplot_kw={'projection':watershed_workflow.crs.to_cartopy(crs)})\n",
    "\n",
    "for huc in list(watershed_orig.polygons()):\n",
    "    axs[0].plot(huc.exterior.xy[0], huc.exterior.xy[1], 'k-x')\n",
    "axs[0].set_title('original river network and hucs',fontsize=16)\n",
    "for huc in list(watershed_simplified.polygons()):\n",
    "    axs[1].plot(huc.exterior.xy[0], huc.exterior.xy[1], 'k-x')\n",
    "axs[1].set_title('after simplify and prune',fontsize=16)\n",
    "for huc in list(watershed.polygons()):\n",
    "    axs[2].plot(huc.exterior.xy[0], huc.exterior.xy[1], 'k-x')\n",
    "axs[2].set_title('re-densified',fontsize=16)\n",
    "axs[2].plot()\n",
    "\n",
    "for river in rivers_orig:\n",
    "    for node in river.preOrder():\n",
    "        x,y=node.segment.xy\n",
    "        axs[0].plot(x,y,'-o',markersize=2)\n",
    "\n",
    "for river in rivers_simplified:\n",
    "    for node in river.preOrder():\n",
    "        x,y=node.segment.xy\n",
    "        axs[1].plot(x,y,'-o',markersize=2)\n",
    "\n",
    "for river in rivers:\n",
    "    for node in river.preOrder():\n",
    "        x,y=node.segment.xy\n",
    "        axs[2].plot(x,y,'-o',markersize=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269e8fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many types of Stream Orders are there\n",
    "set([r.properties[\"StreamOrder\"] for r in rivers[0].preOrder()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74407e2",
   "metadata": {},
   "source": [
    "Widths in the river corridor mesh (quads) is given through dictionary of Stream Order:Width. One way to get these values is to do a quick survey on GIS map and see for the given watershed, what are typical widths of different stream orders. Or, user may also provide width as a function of drainage area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60132952",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Triangulation\n",
    "\n",
    "refine_d0 = 150\n",
    "refine_d1 = 400\n",
    "refine_A0 = 10000\n",
    "refine_A1 = 50000\n",
    "\n",
    "d0 = refine_d0; d1 = refine_d1\n",
    "A0 = refine_A0; A1 = refine_A1\n",
    "\n",
    "# Refine triangles if they get too acute\n",
    "min_angle = 20 # degrees\n",
    "\n",
    "# width of reach by stream order (order:width)\n",
    "widths = dict({2:10,3:20,4:30,5:30})\n",
    "\n",
    "mesh_points2, conn_list, areas, dists = watershed_workflow.tessalate_river_aligned(watershed,rivers, river_width=widths,\n",
    "                                              refine_min_angle=min_angle,refine_distance=[d0,A0,d1,A1],\n",
    "                                              diagnostics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cdc622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a raster for the elevation map, based on NED\n",
    "dem_profile, dem = watershed_workflow.get_raster_on_shape(sources['DEM'], watershed.exterior(), crs)\n",
    "\n",
    "# elevate the triangle nodes to the dem\n",
    "mesh_points3 = watershed_workflow.elevate(mesh_points2, crs, dem, dem_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b8e0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the 2D mesh\n",
    "m2 = watershed_workflow.mesh.Mesh2D(mesh_points3.copy(), conn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa4fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = [shapely.geometry.Polygon(m2.coords[c, :]) for c in m2.conn]\n",
    "area = np.array([shp.area for shp in shapes])\n",
    "small = np.where(area < 500)[0]\n",
    "centroids = m2.centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f7ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_colors = watershed_workflow.colors.enumerated_colors(len(list(watershed.polygons())), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b204eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = watershed_workflow.plot.get_ax(crs)\n",
    "\n",
    "watershed_workflow.plot.hucs(watershed, crs=crs,  ax=ax, facecolor='edge', alpha=0.6)\n",
    "im = watershed_workflow.plot.shplys(shapes, crs, 'elevation', ax, cmap='terrain')\n",
    "sc = ax.scatter(centroids[small,0], centroids[small,1], c=area[small], marker='o', s=20)\n",
    "plt.colorbar(sc)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c452dc4d",
   "metadata": {},
   "source": [
    "In the pit-filling algorithm, we want to make sure that river corridor is not filled up. Hence we exclude river corridor cells from the pit-filling algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbca0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find outlet\n",
    "watershed_workflow.split_hucs.find_outlets_by_crossings(watershed, rivers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04080eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-22T21:34:48.622030Z",
     "iopub.status.busy": "2022-03-22T21:34:48.621481Z",
     "iopub.status.idle": "2022-03-22T21:34:58.682717Z",
     "shell.execute_reply": "2022-03-22T21:34:58.683171Z"
    },
    "papermill": {
     "duration": 11.10124,
     "end_time": "2022-03-22T21:34:58.683420",
     "exception": false,
     "start_time": "2022-03-22T21:34:47.582180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add labeled sets for subcatchments and outlets\n",
    "watershed_workflow.regions.add_watershed_regions_and_outlets(m2, watershed, outlet_width=stream_outlet_width,\n",
    "                                                          labels=[p.properties[huc_key] for p in watershed.polygons()], exterior_outlet= True)\n",
    "\n",
    "# add labeled sets for river corridor cells\n",
    "watershed_workflow.regions.add_river_corridor_regions(m2, rivers)\n",
    "\n",
    "\n",
    "# add labeled sets for river corridor cells by order\n",
    "watershed_workflow.regions.add_regions_by_stream_order_rivers(m2, rivers, labels=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd4b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ls in m2.labeled_sets:\n",
    "    print(f'{ls.setid} : {ls.entity} : {len(ls.ent_ids)} : \"{ls.name}\"')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 654.42164,
   "end_time": "2022-03-22T21:43:12.294817",
   "environment_variables": {},
   "exception": null,
   "input_path": "full_workflow_master.ipynb",
   "output_path": "full_workflow_EastTaylor.ipynb",
   "parameters": {
    "hucs": "[14020001,]",
    "name": "EastTaylor",
    "prune_by_area_fraction": 0.002
   },
   "start_time": "2022-03-22T21:32:17.873177",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
