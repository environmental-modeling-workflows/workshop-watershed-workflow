{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Mixed-Element Mesh for Delineated Watershed\n",
    "\n",
    "This workflow provides a complete working example to develop an streamaligned mixed-element mesh for Coweeta watershed. Long quad elements with pentagons at junctions are placed along NHDPlus flowlines to represent rivers/streams. Rest of the domain is meshed with standard TIN.\n",
    "\n",
    "It uses the following datasets:\n",
    "\n",
    "* `NHD Plus` for the watershed boundary and hydrography.\n",
    "* `NED` for elevation\n",
    "* `NLCD` for land cover/transpiration/rooting depths\n",
    "* `GLYHMPS` geology data for structural formations\n",
    "* `SoilGrids 2017` for depth to bedrock and soil texture information\n",
    "* `SSURGO` for soil data, where available, in the top 2m.\n",
    "\n",
    "This workflow creates the following files:\n",
    "\n",
    "* Mesh file: `Coweeta.exo`, includes all labeled sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing all the package needed to run the watershed workflow\n",
    "# conda package imports\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas\n",
    "from matplotlib import pyplot as plt\n",
    "import logging\n",
    "import pandas as pd\n",
    "import copy\n",
    "import shapely\n",
    "\n",
    "import watershed_workflow\n",
    "import watershed_workflow.source_list\n",
    "import watershed_workflow.ui\n",
    "import watershed_workflow.utils\n",
    "import watershed_workflow.plot\n",
    "import watershed_workflow.mesh\n",
    "import watershed_workflow.densification\n",
    "import watershed_workflow.condition\n",
    "import watershed_workflow.regions\n",
    "watershed_workflow.ui.setup_logging(1,None)\n",
    "\n",
    "# symlink hydrography data:\n",
    "try:\n",
    "    os.symlink('/home/jovyan/data/hydrography',\n",
    "               '/home/jovyan/workdir/notebooks/data/hydrography')\n",
    "except:\n",
    "    print('Symlink for hydrography data already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters cell -- this provides all parameters that can be changed via pipelining to generate a new watershed.\n",
    "coweeta_shapefile = '../Coweeta_data/input_data/coweeta_basin.shp'\n",
    "hint = '0601'  # hint: HUC 4 containing this shape.\n",
    "               # This is necessary to avoid downloading all HUCs to search for this shape\n",
    "name = 'Coweeta'\n",
    "modis_name = None\n",
    "\n",
    "figsize = (6,6)\n",
    "figsize_3d = (8,6)\n",
    "\n",
    "# Geomtric parameters tuning the degree of cleaning of the raw data and scales of hydrologic features to be considered\n",
    "simplify = 60 # length scale to target average edge\n",
    "ignore_small_rivers = 2\n",
    "prune_by_area_fraction = 0.01\n",
    "\n",
    "# huc boundary refinement control\n",
    "refine_d0 = 20\n",
    "refine_d1 = 100\n",
    "refine_L0 = 70\n",
    "refine_L1 = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that, by default, we tend to work in the DayMet CRS because this allows us to avoid\n",
    "# reprojecting meteorological forcing datasets.\n",
    "crs = watershed_workflow.crs.daymet_crs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources and setup\n",
    "\n",
    "Next we set up the source watershed and coordinate system and all data sources for our mesh.  We will use the CRS that is included in the shapefile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A wide range of data sources are available; here we use the defaults except for using NHD Plus for watershed boundaries and hydrography (the default is NHD, which is lower resolution and therefore smaller download sizes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up a dictionary of source objects\n",
    "sources = watershed_workflow.source_list.get_default_sources()\n",
    "sources['hydrography'] = watershed_workflow.source_list.hydrography_sources['NHD Plus']\n",
    "sources['HUC'] = watershed_workflow.source_list.huc_sources['NHD Plus']\n",
    "sources['depth to bedrock'] = watershed_workflow.source_list.FileManagerSoilGrids2017()\n",
    "\n",
    "\n",
    "#\n",
    "# This demo uses a few datasets that have been clipped out of larger, national\n",
    "# datasets and are distributed with the code.  This is simply to save download\n",
    "# time for this simple problem and to lower the barrier for trying out\n",
    "# Watershed Workflow.  A more typical workflow would delete these lines (as\n",
    "# these files would not exist for other watersheds).\n",
    "#\n",
    "# The default versions of these download large raster and shapefile files that\n",
    "# are defined over a very large region (globally or the entire US).\n",
    "#\n",
    "# Note we also prepopulate some data for MODIS data as well.\n",
    "#\n",
    "sources['land cover'] = watershed_workflow.source_list.FileManagerRaster('../Coweeta_data/input_data/land_cover/land_cover.tif')\n",
    "sources['geologic structure'] = watershed_workflow.source_list.FileManagerGLHYMPS('../Coweeta_data/input_data/GLHYMPS/GLHYMPS.shp')\n",
    "sources['depth to bedrock'] = watershed_workflow.source_list.FileManagerRaster('../Coweeta_data/input_data/DTB/DTB.tif')\n",
    "watershed_workflow.source_list.log_sources(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Surface Mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get HUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hucs from shape\n",
    "_, watershed = watershed_workflow.get_split_form_shapes(coweeta_shapefile, out_crs=crs)\n",
    "\n",
    "# note that watershed is now a SplitHUCs object, as described above\n",
    "print(watershed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also look at the polygon corresponding to the watershed\n",
    "watershed.polygon(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and what properties come with this watershed?  Note these were present in the shapefile --\n",
    "# if we had gotten this from NHD or other sources, we would see more properties\n",
    "dict(watershed.polygon(0).properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Rivers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# download/collect reaches (list of LineStrings with properties) that are within the watershed bounds\n",
    "_, reaches = watershed_workflow.get_reaches(sources['hydrography'], hint,\n",
    "                                            watershed.exterior(), crs, crs,\n",
    "                                            in_network=True, properties=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> While constructing river, user should be intentional with prune options to get desired river network density. It is recommended to not have too dense river network if not needed as each reach in the river tree will show up in quad mesh` </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct RiverTree using the collection of reaches\n",
    "rivers = watershed_workflow.construct_rivers(reaches, method='hydroseq',\n",
    "                                                ignore_small_rivers=ignore_small_rivers,\n",
    "                                                prune_by_area=prune_by_area_fraction * watershed.exterior().area * 1.e-6,\n",
    "                                                remove_diversions=True,\n",
    "                                                remove_braided_divergences=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick look at rivers and watershed boundary\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "ax = watershed_workflow.plot.get_ax(crs, fig, window=[0.05,0.1,0.9,0.8])\n",
    "watershed_workflow.plot.hucs(watershed, crs, 'k', ax)\n",
    "watershed_workflow.plot.rivers(rivers, crs, 'b', ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplify and Redensify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> In the simplification step below, we keep the original river so that we can sample vertices from these original dense rivers and huc boundaries to get vertex density at desired resolution. </b>\n",
    "\n",
    "Using the Douglas-Peucker algorithm, we simplify the flowline by removing non-essential vertices with shapely's \"simplify\" method, ensuring accurate representation. Additional simplifications, such as merging minor reaches and aligning watershed boundaries with flowlines, are also performed. The process is demonstrated in the figure below:\n",
    "\n",
    "![Optional Alt Text](./images/densification.png)\n",
    "\n",
    "TIPS:\n",
    "- keep merge tolerance about 70% of the simplify_rivers tolerance\n",
    "- use smaller snap tolerance 50% of simplify_rivers if non-outlet reaches start snapping to the watershed boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping the originals\n",
    "rivers_orig=[river.deepcopy() for river in rivers]\n",
    "watershed_orig=copy.deepcopy(watershed)\n",
    "\n",
    "# simplifying\n",
    "rivers = watershed_workflow.simplify(watershed, rivers, simplify_hucs=simplify, simplify_rivers=simplify,\n",
    "                            merge_tol=0.7*simplify, snap_tol=0.5*simplify, cut_intersections=True)\n",
    "\n",
    "# for plotting purpose only\n",
    "rivers_simplified=[river.deepcopy() for river in rivers]\n",
    "watershed_simplified=copy.deepcopy(watershed)\n",
    "\n",
    "print('number of reaches in original', len(rivers_orig[0]), 'number of reaches in simplified', len(rivers[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see what changed between original and simplified river\n",
    "\n",
    "fig, axs = plt.subplots(1,2,subplot_kw={'projection':watershed_workflow.crs.to_cartopy(crs)}, figsize=(10,10))\n",
    "\n",
    "axs[0].plot(watershed_orig.exterior().exterior.xy[0], watershed_orig.exterior().exterior.xy[1], 'k-x')\n",
    "axs[0].set_title('original river network and hucs',fontsize=16)\n",
    "axs[1].plot(watershed.exterior().exterior.xy[0], watershed.exterior().exterior.xy[1], 'k-x')\n",
    "axs[1].set_title('after simplify and prune',fontsize=16)\n",
    "\n",
    "for river in rivers_orig:\n",
    "    for node in river.preOrder():\n",
    "        x,y=node.segment.xy\n",
    "        axs[0].plot(x,y,'-o',markersize=5)\n",
    "\n",
    "for river in rivers_simplified:\n",
    "    for node in river.preOrder():\n",
    "        x,y=node.segment.xy\n",
    "        axs[1].plot(x,y,'-o',markersize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>In step two, we enhance the flowline and watershed boundary resolution by adding nearly uniformly distributed vertices, sampled from the original to regain any curvature lost during simplification. </b> \n",
    "\n",
    "User provides an upper limit that dictates the distance between two consecutive vertices on the reach segment and ultimately determine the quad length in the river mesh. When this distance in a reach segment, represented as a `shapely.LineString` object, exceeds this scale, additional vertices are inserted. Their number and coordinates are derived using 1D interpolation from the original segment vertices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#densify_river\n",
    "watershed_workflow.densification.densify_rivers(rivers, rivers_orig, limit=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The limit on the distance between vertices on the huc boundary is a function of distance from the river. Parts of huc segments close to river get vertices placed at higher density. \n",
    "\n",
    "TIPS:\n",
    "\n",
    "- provide L0 about same as length scale limit on river and  L1 about 1.5 to 2 times times length scale limit on river\n",
    "- profile d1 atleast equal to length scale limit on river"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = refine_d0; d1 = refine_d1\n",
    "L0 = refine_L0; L1 = refine_L1\n",
    "\n",
    "# densify_watershed\n",
    "watershed_workflow.densification.densify_hucs(watershed, watershed_orig, rivers, limit_scales=[d0,L0,d1,L1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sharp bends in the river and tributaries running closely before merging are a couple of cases that can constrain triangulation to yield small triangles. Hence, we smoothen out some of these sharp angles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treat sharp angles\n",
    "watershed_workflow.densification.remove_sharp_angles(rivers, watershed, angle_limit=10, junction_angle_limit=10, huc_seg_river_angle_limit=10, limit=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## quick look at what we did in simplify and redensification step\n",
    "\n",
    "seg = rivers_orig[0].segment # trimming the reach outside the waterhed in the original river to make figure look clean\n",
    "rivers_orig[0].segment = shapely.geometry.LineString(seg.coords[:70])\n",
    "\n",
    "fig, axs = plt.subplots(1,3,subplot_kw={'projection':watershed_workflow.crs.to_cartopy(crs)}, figsize=(15,12))\n",
    "\n",
    "axs[0].plot(watershed_orig.exterior().exterior.xy[0], watershed_orig.exterior().exterior.xy[1], 'k-x')\n",
    "axs[0].set_title('original river and watershed',fontsize=16)\n",
    "axs[1].plot(watershed_simplified.exterior().exterior.xy[0], watershed_simplified.exterior().exterior.xy[1], 'k-x')\n",
    "axs[1].set_title('after simplification',fontsize=16)\n",
    "axs[2].plot(watershed.exterior().exterior.xy[0], watershed.exterior().exterior.xy[1], 'k-x')\n",
    "axs[2].set_title('re-sampled',fontsize=16)\n",
    "axs[2].plot()\n",
    "\n",
    "ax2 = axs[2].inset_axes([0.65,0.05,0.3,0.3])\n",
    "ax3= axs[2].inset_axes([0.05,0.68,0.3,0.3])\n",
    "\n",
    "ax2.set_aspect('equal', 'datalim')\n",
    "ax3.set_aspect('equal', 'datalim')\n",
    "ax2.plot(watershed.exterior().exterior.xy[0], watershed.exterior().exterior.xy[1], 'k-x')\n",
    "ax3.plot(watershed.exterior().exterior.xy[0], watershed.exterior().exterior.xy[1], 'k-x')\n",
    "\n",
    "for river in rivers_orig:\n",
    "    for node in river.preOrder():\n",
    "        x,y=node.segment.xy\n",
    "        axs[0].plot(x,y,'-o',markersize=2)\n",
    "\n",
    "for river in rivers_simplified:\n",
    "    for node in river.preOrder():\n",
    "        x,y=node.segment.xy\n",
    "        axs[1].plot(x,y,'-o',markersize=2)\n",
    "\n",
    "for river in rivers:\n",
    "    for node in river.preOrder():\n",
    "        x,y=node.segment.xy\n",
    "        axs[2].plot(x,y,'-o',markersize=2)\n",
    "        ax2.plot(x,y,'-o',markersize=2)\n",
    "        ax3.plot(x,y,'-o',markersize=2)\n",
    "\n",
    "\n",
    "xlim = (1.4433e6, 1.4438e6)\n",
    "ylim = (-647500, -647000)\n",
    "ax2.set_xlim(xlim)\n",
    "ax2.set_ylim(ylim)\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "\n",
    "delx=3000\n",
    "dely= 1000\n",
    "xlim = (1.4433e6+delx+100, 1.4438e6+delx-100)\n",
    "ylim = (-647500+dely+100, -647000+dely-100)\n",
    "ax3.set_xlim(xlim)\n",
    "ax3.set_ylim(ylim)\n",
    "ax3.set_xticks([])\n",
    "ax3.set_yticks([])\n",
    "\n",
    "axs[2].indicate_inset_zoom(ax2, edgecolor='k')\n",
    "axs[2].indicate_inset_zoom(ax3, edgecolor='k')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meshing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stream-aligned quad-elements get their width from given through dictionary of Stream Order:Width. One way to get these values is to do a quick survey on GIS map and see for the given watershed, what are typical widths of different stream orders. Or, user may also provide width as a function of drainage area. \n",
    "\n",
    "<b> Select widths that ensures the aspect ratio of the quadrilateral elements remains elongated. This is important to avoid potential complications in defining the mesh topology. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many types of Stream Orders are there\n",
    "import matplotlib.patches as mpatches\n",
    "stream_orders = set([r.properties[\"StreamOrder\"] for r in rivers[0].preOrder()])\n",
    "\n",
    "colors=dict(zip(set(n.properties['StreamOrder'] for n in river.preOrder()),\n",
    "                watershed_workflow.colors.enumerated_colors(len(stream_orders))))\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "ax = watershed_workflow.plot.get_ax(crs, fig, window=[0.05,0.1,0.9,0.8])\n",
    "watershed_workflow.plot.hucs(watershed, ax=ax, color= 'k', crs=crs)\n",
    "for river in rivers:\n",
    "    for node in river.preOrder():\n",
    "        watershed_workflow.plot.shply(node.segment, ax=ax, crs=crs, color=colors[node.properties['StreamOrder']])\n",
    "\n",
    "# Create a list of patches for the legend\n",
    "legend_patches = [mpatches.Patch(color=colors[n], label=f'Stream Order {n}') for n in stream_orders]\n",
    "\n",
    "# Add the legend to the plot\n",
    "ax.legend(handles=legend_patches, bbox_to_anchor = (1,1) )  # You can change the location as needed\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Tessellation</b> process involes following steps:\n",
    "\n",
    "- Creation of river-corridor polygon with prescribed widths\n",
    "- Triangulation with river-corridor polygon as a hole (with no steiner points allowed). We also provide mesh quality criteria like criteria like angle and area constraints \n",
    "- Appending river-mesh elements to TIN-mesh elements creating a complete stream-aligned mixed-element mesh\n",
    "\n",
    "![Optional Alt Text](./images/coweeta_workflow.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Triangulation\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8, 4]\n",
    "\n",
    "# Refine triangles if their area exceeds the limits prescribed below\n",
    "refine_d0 = 100\n",
    "refine_d1 = 250\n",
    "refine_A0 = 2500\n",
    "refine_A1 = 30000\n",
    "\n",
    "d0 = refine_d0; d1 = refine_d1\n",
    "A0 = refine_A0; A1 = refine_A1\n",
    "\n",
    "# Refine triangles if they get too acute\n",
    "min_angle = 32 # degrees\n",
    "\n",
    "# width of reach by stream order (order:width)\n",
    "widths = dict({1:8,2:12,3:16})\n",
    "\n",
    "mesh_points2, conn_list, areas, dists = watershed_workflow.tessalate_river_aligned(watershed,rivers, river_width=widths,\n",
    "                                                refine_distance=[d0,A0,d1,A1],\n",
    "                                                refine_min_angle=min_angle,\n",
    "                                                diagnostics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a raster for the elevation map, based on NED\n",
    "dem_profile, dem = watershed_workflow.get_raster_on_shape(sources['DEM'], watershed.exterior(), crs)\n",
    "\n",
    "# elevate the triangle nodes to the dem\n",
    "mesh_points3 = watershed_workflow.elevate(mesh_points2, crs, dem, dem_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the 2D mesh\n",
    "m2 = watershed_workflow.mesh.Mesh2D(mesh_points3.copy(), conn_list)\n",
    "\n",
    "m2_unconditioned = copy.deepcopy(m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hydrologic Conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the <b>pit-filling</b> algorithm, we want to make sure that river corridor is not filled up. Hence we exclude river corridor cells from the pit-filling algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing pits\n",
    "river_mask=np.zeros((len(m2.conn)))\n",
    "for i, elem in enumerate(m2.conn):\n",
    "    if not len(elem)==3:\n",
    "        river_mask[i]=1\n",
    "watershed_workflow.condition.fill_pits_dual(m2, is_waterbody=river_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Hydrologic conditioning </b> step ensures connectivity in the stream network by removing spurrious obstructions and enforcing elevation gradients\n",
    "\n",
    "\n",
    "- `smooth`: boolean, optional </br>\n",
    "        If true, smooth the profile of each reach using a gaussian\n",
    "        filter (mainly to pass through railroads and avoid reservoirs).\n",
    "- `use_parent`: boolean, optional\n",
    "        If true, use the segment from the original parent reach while\n",
    "        smoothing (seems to be not making a huge difference).\n",
    "- `lower`: boolean, optional</br>\n",
    "        If true, lower the smoothed bed profile to match the lower\n",
    "        points on the raw bed profile. This is useful particularly for\n",
    "        narrow ag. ditches where NHDPLus flowlines often do not\n",
    "        coincide with the DEM depressions and so stream-elements\n",
    "        intermitently fall into them.\n",
    "- `use_nhd_elev`: boolean, optional</br>\n",
    "        If true, enforce maximum and minimum elevation for each\n",
    "        reach provided in NHDPlus.\n",
    "- `treat_banks`: boolean, optional</br>\n",
    "        Where the river is passing right next to the reservoir or\n",
    "        NHDline is misplaced into the reservoir, banks may fall into\n",
    "        the reservoir. If true, this will enforce that the bank node\n",
    "        is at a higher elevation than the stream bed elevation.\n",
    "- `depress_upstream_by`: float, optional</br>\n",
    "        If the depression is not captured well in the DEM, the\n",
    "        river-mesh elements (streambed) headwater reaches may be\n",
    "        lowered by this number.  The effect of propogated downstream\n",
    "        only upto where it is needed to maintain topographic gradients\n",
    "        on the network scale in the network sweep step.\n",
    "- `network_burn_in_depth`: float, dict, or function</br>\n",
    "        Like depress_upstream_by, this also lowers river-mesh elements\n",
    "        by this value, but this variant lowers all reaches.  The depth\n",
    "        may be provided as a float (uniform lowering), dictionary\n",
    "        {stream order : depth to depress by}, or as a function of\n",
    "        drainage area.\n",
    "- `ignore_in_sweep`: list, optional</br>\n",
    "        If provided, a list of IDs to not be burned in via the network\n",
    "        sweep.\n",
    "\n",
    "\n",
    "Examples of hydrology conditioning:\n",
    "\n",
    "![hydro_condition](./images/hydro_conditioning.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditioning river mesh\n",
    "\n",
    "# adding elevations to the river tree for stream bed conditioning\n",
    "watershed_workflow.condition.elevate_rivers(rivers, crs, dem, dem_profile)\n",
    "\n",
    "# conditioning the river mesh using NHD elevations\n",
    "watershed_workflow.condition.condition_river_mesh(m2, river) #  network_burn_in_depth=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting surface mesh with elevations\n",
    "start=min(m2.centroids[:,2])\n",
    "step=(max(m2.centroids[:,2])-(min(m2.centroids[:,2])))/40\n",
    "stop=max(m2.centroids[:,2])+step\n",
    "legend_values=np.arange(start,stop,step)\n",
    "indices, cmap, norm, ticks, labels = watershed_workflow.colors.generate_indexed_colormap(legend_values, cmap='jet')\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = watershed_workflow.plot.get_ax(crs, fig, window=[0.05,0.1,0.9,0.8])\n",
    "ax2 = ax.inset_axes([0.65,0.05,0.3,0.5])\n",
    "cbax = fig.add_axes([0.05,0.05,0.9,0.05])\n",
    "\n",
    "mp = watershed_workflow.plot.mesh(m2, crs, ax=ax,\n",
    "                        linewidth=0.5 ,color=m2.centroids[:,2],\n",
    "                        cmap=cmap, norm = norm, edgecolor='k', facecolor='color')\n",
    "cbar = fig.colorbar(mp, orientation=\"horizontal\", cax=cbax)\n",
    "ax.set_title('surface mesh with elevations')\n",
    "ax.set_aspect('equal', 'datalim')\n",
    "\n",
    "mp2 = watershed_workflow.plot.mesh(m2, crs, ax=ax2,\n",
    "                        linewidth=0.5 ,color=m2.centroids[:,2],\n",
    "                        cmap=cmap, norm = norm, edgecolor='k', facecolor='color')\n",
    "ax2.set_aspect('equal', 'datalim')\n",
    "\n",
    "xlim = (1.4433e6, 1.4438e6)\n",
    "ylim = (-647000, -647500)\n",
    "\n",
    "ax2.set_xlim(xlim)\n",
    "ax2.set_ylim(ylim)\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "\n",
    "ax.indicate_inset_zoom(ax2, edgecolor='k')\n",
    "cbar.ax.set_title('elevation [m]')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the change between the two meshes\n",
    "diff = m2.centroids[:,2] - m2_unconditioned.centroids[:,2]\n",
    "print(\"max diff = \", np.abs(diff).max())\n",
    "\n",
    "# plotting surface mesh with elevations\n",
    "start=min(diff)\n",
    "step=(max(diff)-(min(diff)))/10\n",
    "stop=max(diff)+step\n",
    "legend_values=np.arange(start,stop,step)\n",
    "indices, cmap, norm, ticks, labels = watershed_workflow.colors.generate_indexed_colormap(legend_values, cmap='jet')\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = watershed_workflow.plot.get_ax(crs, fig, window=[0.05,0.1,0.9,0.8])\n",
    "cbax = fig.add_axes([0.05,0.05,0.9,0.05])\n",
    "mp = watershed_workflow.plot.mesh(m2, crs, ax=ax,\n",
    "                        linewidth=0.5 ,color=diff,\n",
    "                        cmap=cmap, norm = norm, edgecolor='k', facecolor='color')\n",
    "cbar = fig.colorbar(mp, orientation=\"horizontal\", cax=cbax)\n",
    "ax.set_title('surface mesh with elevations')\n",
    "ax.set_aspect('equal', 'datalim')\n",
    "\n",
    "ax.set_title('conditioned dz')\n",
    "cbar.ax.set_title('elevation diff [m]')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------------------------------------------------------------\n",
    "## Questions? \n",
    "### -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LabeledSets and Regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface properties\n",
    "\n",
    "Meshes interact with data to provide forcing, parameters, and more in the actual simulation.  Specifically, we need vegetation type on the surface to provide information about transpiration and subsurface structure to provide information about water retention curves, etc.\n",
    "\n",
    "We'll start by downloading and collecting land cover from the NLCD dataset, and generate sets for each land cover type that cover the surface.  Likely these will be some combination of grass, deciduous forest, coniferous forest, and mixed forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the NLCD raster\n",
    "lc_profile, lc_raster = watershed_workflow.get_raster_on_shape(sources['land cover'],\n",
    "                                                     watershed.exterior(), crs)\n",
    "\n",
    "# resample the raster to the triangles\n",
    "lc = watershed_workflow.values_from_raster(m2.centroids, crs, lc_raster, lc_profile)\n",
    "\n",
    "# what land cover types did we get?\n",
    "logging.info('Found land cover dtypes: {}'.format(lc.dtype))\n",
    "logging.info('Found land cover types: {}'.format(set(lc)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the NLCD data\n",
    "\n",
    "# -- get the NLCD colormap which uses official NLCD colors and labels\n",
    "nlcd_indices, nlcd_cmap, nlcd_norm, nlcd_ticks, nlcd_labels = \\\n",
    "                watershed_workflow.colors.generate_nlcd_colormap(lc)\n",
    "\n",
    "# plot the image\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = watershed_workflow.plot.get_ax(crs, fig)\n",
    "\n",
    "polys = watershed_workflow.plot.mesh(m2, crs, ax=ax, color=lc, cmap=nlcd_cmap,\n",
    "                                     norm=nlcd_norm, edgecolor='none',\n",
    "                                     facecolor='color', linewidth=0.5)\n",
    "watershed_workflow.colors.colorbar_index(ncolors=len(nlcd_indices), cmap=nlcd_cmap,\n",
    "                                         labels=nlcd_labels, cax=fig.add_axes(rect=[0.9,0.1,0.05,0.8]))\n",
    "ax.set_title(\"NLCD land cover index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add regions for the land cover types, river corridor and reaches of each order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labeled sets to the mesh for NLCD\n",
    "nlcd_labels_dict = dict(zip(nlcd_indices, nlcd_labels))\n",
    "watershed_workflow.regions.add_nlcd_labeled_sets(m2, lc, nlcd_labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add labeled sets for river corridor cells\n",
    "watershed_workflow.regions.add_river_corridor_regions(m2, rivers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add labeled sets for river corridor cells for reaches each stream order\n",
    "watershed_workflow.regions.add_regions_by_stream_order_rivers(m2, rivers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ls in m2.labeled_sets:\n",
    "    print(f'{ls.setid} : {ls.entity} : {len(ls.ent_ids)} : \"{ls.name}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsurface properties\n",
    "\n",
    "The default model uses GLHYMPS to identify geologic formations, and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the NRCS soils data as shapes and project it onto the mesh\n",
    "#\n",
    "soil_profile, soil_survey, soil_survey_props = \\\n",
    "        watershed_workflow.get_shapes(sources['soil structure'], list(watershed.polygons()), crs,\n",
    "                                                     crs, properties=True)\n",
    "\n",
    "# -- determine the NRCS mukey for each soil unit; this uniquely identifies soil\n",
    "#    properties\n",
    "soil_ids = list(soil_survey_props['mukey'][:])\n",
    "soil_survey_props.set_index('mukey', inplace=True)\n",
    "\n",
    "# -- color a raster by the polygons (this makes identifying a triangle's value much\n",
    "#    more efficient)\n",
    "soil_color_profile, soil_color_raster = watershed_workflow.color_raster_from_shapes(soil_survey, crs, soil_ids,\n",
    "                                                                                    watershed.exterior().bounds, 10, crs, -1)\n",
    "\n",
    "# -- resample the raster to the triangles\n",
    "soil_color = watershed_workflow.values_from_raster(m2.centroids, crs,\n",
    "                                         soil_color_raster, soil_color_profile)\n",
    "soil_survey_props"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only the soils within the watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the soil mukey\n",
    "indices, cmap, norm, ticks, labels = watershed_workflow.colors.generate_indexed_colormap(soil_color, cmap='tab20c')\n",
    "fig, ax = watershed_workflow.plot.get_ax(crs)\n",
    "\n",
    "mp = watershed_workflow.plot.mesh(m2, crs, ax=ax, facecolor='color',\n",
    "                        linewidth=0, color=soil_color,\n",
    "                        cmap=cmap, norm = norm\n",
    "                       )\n",
    "\n",
    "watershed_workflow.colors.colorbar_index(ncolors=len(np.unique(soil_color)), cmap=cmap, labels=labels, cax=fig.add_axes(rect=[0.9,0.1,0.05,0.8]))\n",
    "\n",
    "ax.set_title('soil type index')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does soil thickness look like?\n",
    "soil_thickness = np.empty(soil_color.shape, 'd')\n",
    "for mukey in soil_survey_props.index:\n",
    "    soil_thickness[soil_color == mukey] = soil_survey_props.loc[mukey,'thickness [cm]']\n",
    "\n",
    "soil_thickness = soil_thickness / 100\n",
    "indices, cmap, norm, ticks, labels = watershed_workflow.colors.generate_indexed_colormap(soil_thickness, cmap='jet')\n",
    "fig, ax = watershed_workflow.plot.get_ax(crs, figsize=figsize)\n",
    "mp = watershed_workflow.plot.mesh(m2, crs, ax=ax, facecolor='color',\n",
    "                        linewidth=0.5, color=soil_thickness,\n",
    "                        cmap=cmap                       )\n",
    "ax.set_title('soil thickness [m]')\n",
    "cb = fig.colorbar(mp, fraction=0.04, pad=0.04, extend = \"both\", shrink = 0.6)\n",
    "#watershed_workflow.colors.colorbar_index(ncolors=len(np.unique(soil_thickness))//10, cmap=cmap, labels = labels)\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "print('Median soil thickness [-] = ', np.nanmedian(soil_thickness))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of porosity from SSURGO\n",
    "iprop = np.empty(soil_color.shape, 'd')\n",
    "for mukey in soil_survey_props.index:\n",
    "    iprop[soil_color == mukey] = soil_survey_props.loc[ mukey,'porosity [-]']\n",
    "indices, cmap, norm, ticks, labels = watershed_workflow.colors.generate_indexed_colormap(iprop, cmap='jet')\n",
    "fig, ax = watershed_workflow.plot.get_ax(crs, figsize=figsize)\n",
    "mp = watershed_workflow.plot.mesh(m2, crs, ax=ax,\n",
    "                        linewidth=0.5, color=iprop, cmap=cmap, facecolor='color')\n",
    "ax.set_title('soil porosity [-]')\n",
    "cb = fig.colorbar(mp, fraction=0.04, pad=0.04, extend = \"both\", shrink = 0.6)\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "print('Median porosity [-] = ', np.nanmedian(iprop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of permeability\n",
    "iprop = np.empty(soil_color.shape, 'd')\n",
    "for mukey in soil_survey_props.index:\n",
    "    iprop[soil_color == mukey] = soil_survey_props.loc[ mukey,'permeability [m^2]']\n",
    "\n",
    "indices, cmap, norm, ticks, labels = watershed_workflow.colors.generate_indexed_colormap(np.log10(iprop), cmap='jet')\n",
    "fig, ax = watershed_workflow.plot.get_ax(crs)\n",
    "mp = watershed_workflow.plot.mesh(m2, crs, ax=ax,\n",
    "                        linewidth=0,color=np.log10(iprop),cmap=cmap, facecolor='color')\n",
    "ax.set_title('soil permeability [-]')\n",
    "cb = fig.colorbar(mp, fraction=0.04, pad=0.04, extend = \"both\", shrink = 0.6)\n",
    "cb.ax.set_title('log K')\n",
    "ax.axis('off')\n",
    "print('Min k [m^2] = ', np.nanmin(iprop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the missing data (white).  This is because some SSURGO map units have no formation with complete\n",
    "# information.  So we merge the above available data, filling where possible and dropping regions that\n",
    "# do not have a complete set of properties.\n",
    "soil_survey_props_clean = soil_survey_props.reset_index()\n",
    "\n",
    "# later scripts expect 'native_index' as a standard name of holding onto the original IDs\n",
    "soil_survey_props_clean.rename_axis('native_index', inplace=True)\n",
    "soil_survey_props_clean.rename(columns={'mukey':'native_index'}, inplace=True)\n",
    "\n",
    "# need thickness in m\n",
    "soil_survey_props_clean['thickness [cm]'] = soil_survey_props_clean['thickness [cm]']/100.\n",
    "soil_survey_props_clean.rename(columns={'thickness [cm]':'thickness [m]'}, inplace=True)\n",
    "\n",
    "\n",
    "def replace_column_nans(df, col_nan, col_replacement):\n",
    "    \"\"\"In a df, replace col_nan entries by col_replacement if is nan.  In Place!\"\"\"\n",
    "    row_indexer = df[col_nan].isna()\n",
    "    df.loc[row_indexer, col_nan] = df.loc[row_indexer, col_replacement]\n",
    "    return\n",
    "\n",
    "# where poro or perm is nan, put Rosetta poro\n",
    "replace_column_nans(soil_survey_props_clean, 'porosity [-]', 'Rosetta porosity [-]')\n",
    "replace_column_nans(soil_survey_props_clean, 'permeability [m^2]', 'Rosetta permeability [m^2]')\n",
    "\n",
    "# drop unnecessary columns\n",
    "for col in ['Rosetta porosity [-]', 'Rosetta permeability [m^2]', 'bulk density [g/cm^3]', 'total sand pct [%]',\n",
    "            'total silt pct [%]', 'total clay pct [%]']:\n",
    "    soil_survey_props_clean.pop(col)\n",
    "\n",
    "# drop nans\n",
    "soil_survey_props_clean.dropna(inplace=True)\n",
    "soil_survey_props_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "soil_survey_props_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new soil_color, keeping on those that are kept here and re-indexing to ATS indices\n",
    "soil_color_new = -np.ones_like(soil_color)\n",
    "for new_id, mukey in enumerate(soil_survey_props_clean['native_index']):\n",
    "    soil_color_new[np.where(soil_color == mukey)] = 1000+new_id\n",
    "\n",
    "\n",
    "# image the new soil_color\n",
    "indices, cmap, norm, ticks, labels = watershed_workflow.colors.generate_indexed_colormap(soil_color_new, cmap='tab20c')\n",
    "fig, ax = watershed_workflow.plot.get_ax(crs)\n",
    "\n",
    "mp = watershed_workflow.plot.mesh(m2, crs, ax=ax, facecolor='color',\n",
    "                    linewidth=0, color=soil_color_new,\n",
    "                    cmap=cmap, norm=norm)\n",
    "\n",
    "watershed_workflow.colors.colorbar_index(ncolors=len(np.unique(soil_color_new)), cmap=cmap, labels=labels, cax = fig.add_axes(rect=[0.9,0.1,0.05,0.8]))\n",
    "\n",
    "ax.set_title('soil type index')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLYHMPS geologic layer\n",
    "\n",
    "GLYHMPS is complete in that it does not appear to have missing data, but does not have texture properties needed for Water Retention Models.  Instead we rely on scaling laws to fill the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the GLYHMPS geologic structure data as shapes and project it onto the mesh\n",
    "target_bounds = watershed.exterior().bounds\n",
    "logging.info('target bounds: {}'.format(target_bounds))\n",
    "\n",
    "_, geo_survey, geo_survey_props = watershed_workflow.get_shapes(sources['geologic structure'],\n",
    "                                                      target_bounds, crs, crs, properties=True)\n",
    "\n",
    "# -- log the bounds targeted and found\n",
    "logging.info('shape union bounds: {}'.format(\n",
    "    shapely.ops.cascaded_union(geo_survey).bounds))\n",
    "\n",
    "# -- determine the ID for each soil unit; this uniquely identifies formation\n",
    "#    properties\n",
    "geo_ids = np.array([shp.properties['id'] for shp in geo_survey], np.int32)\n",
    "\n",
    "# -- color a raster by the polygons (this makes identifying a triangle's value much\n",
    "#    more efficient)\n",
    "geo_color_profile, geo_color_raster = \\\n",
    "            watershed_workflow.color_raster_from_shapes(geo_survey, crs, geo_ids,\n",
    "                                                        target_bounds, 10, crs, -1)\n",
    "\n",
    "# -- resample the raster to the triangles\n",
    "geo_color = watershed_workflow.values_from_raster(m2.centroids, crs,\n",
    "                                         geo_color_raster, geo_color_profile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the properties that appear in the mesh\n",
    "geo_survey_props.set_index('id', inplace=True, drop=False)\n",
    "geo_survey_props = geo_survey_props.loc[np.unique(geo_color), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the geologic formation id\n",
    "indices, cmap, norm, ticks, labels = watershed_workflow.colors.generate_indexed_colormap(geo_color, cmap='tab20b')\n",
    "\n",
    "fig, ax = watershed_workflow.plot.get_ax(crs)\n",
    "\n",
    "mp = watershed_workflow.plot.mesh(m2, crs, ax=ax, facecolor='color',\n",
    "                    linewidth=0, color=geo_color,\n",
    "                    cmap=cmap, norm=norm)\n",
    "\n",
    "watershed_workflow.colors.colorbar_index(ncolors=len(np.unique(geo_color)), cmap=cmap, labels=labels, cax=fig.add_axes(rect=[0.9,0.1,0.05,0.8]))\n",
    "\n",
    "ax.set_title('geol type index')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot permeability of the underlying geologic layer\n",
    "iprop = np.empty(geo_color.shape, 'd')\n",
    "for i in geo_survey_props.index:\n",
    "    iprop[geo_color == i] = geo_survey_props.loc[i, 'permeability [m^2]']\n",
    "\n",
    "indices, cmap, norm, ticks, labels = watershed_workflow.colors.generate_indexed_colormap(np.log10(iprop), cmap='jet')\n",
    "fig, ax = watershed_workflow.plot.get_ax(crs)\n",
    "mp = watershed_workflow.plot.mesh(m2, crs, ax=ax,\n",
    "                        linewidth=0.5,color=np.log10(iprop),cmap=cmap, facecolor='color')\n",
    "cbar = fig.colorbar(mp, shrink=0.5)\n",
    "ax.set_title('geology log permeability [m^2]')\n",
    "ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot porosity of the geologic layer\n",
    "iprop = np.empty(geo_color.shape, 'd')\n",
    "for i in geo_survey_props.index:\n",
    "    iprop[geo_color == i] = geo_survey_props.loc[i, 'porosity [-]']\n",
    "\n",
    "indices, cmap, norm, ticks, labels = watershed_workflow.colors.generate_indexed_colormap(iprop, cmap='jet')\n",
    "fig, ax = watershed_workflow.plot.get_ax(crs)\n",
    "mp = watershed_workflow.plot.mesh(m2, crs, ax=ax,\n",
    "                        linewidth=0.5,color=np.log10(iprop),cmap=cmap, facecolor='color')\n",
    "cbar = fig.colorbar(mp, shrink=0.5)\n",
    "ax.set_title('geology porosity [-]')\n",
    "ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note there are clearly some common regions -- no need to duplicate those with identical values.\n",
    "geo_survey_props_clean = geo_survey_props.copy()\n",
    "geo_survey_props_clean.pop('logk_stdev [-]')\n",
    "geo_survey_props_clean.rename(columns={'id':'native_index'}, inplace=True)\n",
    "\n",
    "\n",
    "def reindex_remove_duplicates(df, index=None):\n",
    "    \"\"\"Removes duplicates, creating a new index and saving the old index as tuples of duplicate values. In place!\"\"\"\n",
    "    if index is not None:\n",
    "        if index in df:\n",
    "            df.set_index(index, drop=True, inplace=True)\n",
    "\n",
    "    index_name = df.index.name\n",
    "\n",
    "    # identify duplicate rows\n",
    "    duplicates = list(df.groupby(list(df)).apply(lambda x: tuple(x.index)))\n",
    "\n",
    "    # order is preserved\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    df[index_name] = duplicates\n",
    "    return\n",
    "\n",
    "reindex_remove_duplicates(geo_survey_props_clean, 'native_index')\n",
    "geo_survey_props_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new geologic layer color, keeping on those that are kept here and re-indexing to ATS indices\n",
    "geo_color_new = -np.ones_like(geo_color)\n",
    "for new_id, old_id_dups in enumerate(geo_survey_props_clean['native_index']):\n",
    "    for old_id in old_id_dups:\n",
    "        geo_color_new[np.where(geo_color == old_id)] = 100+new_id\n",
    "\n",
    "# image the new geo_color\n",
    "indices, cmap, norm, ticks, labels = watershed_workflow.colors.generate_indexed_colormap(geo_color_new, cmap='tab20c')\n",
    "fig, ax = watershed_workflow.plot.get_ax(crs)\n",
    "\n",
    "mp = watershed_workflow.plot.mesh(m2, crs, ax=ax, facecolor='color',\n",
    "                    linewidth=0, color=geo_color_new,\n",
    "                    cmap=cmap, norm=norm)\n",
    "\n",
    "watershed_workflow.colors.colorbar_index(ncolors=len(np.unique(geo_color_new)), cmap=cmap, labels=labels, cax=fig.add_axes(rect=[0.9,0.1,0.05,0.8]))\n",
    "\n",
    "ax.set_title('geologic type index')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth-to-bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depth to bedrock is taken from the [SoilGrids](http://globalchange.bnu.edu.cn/research/dtb.jsp) product.  Here we download a US-based, clipped version of this global product, as file sizes are quite large (all products potentially used total over 100GB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTB_profile, DTB_raster = watershed_workflow.get_raster_on_shape(sources['depth to bedrock'], watershed.exterior(), crs,\n",
    "                                                       nodata=-99999)\n",
    "\n",
    "# resample the raster to the triangles\n",
    "DTB_raster = DTB_raster/100 #convert from cm to m\n",
    "DTB = watershed_workflow.values_from_raster(m2.centroids, crs, DTB_raster, DTB_profile, algorithm='piecewise bilinear')\n",
    "DTB = np.where(DTB >= 0, DTB, np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the resulting surface mesh\n",
    "fig, ax = watershed_workflow.plot.get_ax(crs, window=[0.05,0.1,0.9,0.8])\n",
    "cbax = fig.add_axes([.95,0.1,0.05,0.8])\n",
    "\n",
    "indices, cmap, norm, ticks, labels = watershed_workflow.colors.generate_indexed_colormap(DTB, cmap='plasma_r')\n",
    "mp = watershed_workflow.plot.mesh(m2, crs, ax=ax,\n",
    "                        linewidth=0,color=DTB,cmap=cmap, facecolor='color')\n",
    "cbar = fig.colorbar(mp, orientation=\"vertical\", cax=cbax)\n",
    "\n",
    "ax.set_aspect('equal', 'datalim')\n",
    "ax.axis('off')\n",
    "\n",
    "cbar.ax.set_title('DTB [m]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A combined, complete product?\n",
    "\n",
    "As a default, we would like a material-driven (e.g. not fields for porosity, perm, etc, but soil classes, each with a common porosity/permeability/vG curve) default that is valid everywhere.  That makes it clear that we must rely on GLHYMPS as the only material-based product that is valid everywhere.  Other products may be layered on top of this, replacing GLHYMPS values, but the underlying layer should be based on GLHYMPS.  To fill in the van Genuchten properties, we relate alpha to permeability and choose a single common n and s_r.\n",
    "\n",
    "Where available, we then choose to use SSURGO as a layer on top of GLHYMPS.  So start by using all GLHYMPS values, then override ones where SSURGO is valid with those values.  This will be the second model, and has then three layers -- a bedrock layer, a soil layer from 0 to 2m, and a geologic layer, using GLHYMPS values.  SoilGrids depth-to-bedrock will be used to provide the transition between bedrock and (where > 2m) the GLHYMPS \"geologic\" layer or (where < 2m) the SSURGO \"soil\" layer.  Where SSURGO has no values, the underlying GLHYMPS values will be used even in the top 2m.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First, all integer IDs in Exodus files must be unique.  This includes Material IDs, side sets, etc.  We create the Material ID map and data frame.  This is used to standardize IDs from multiple data sources.  Traditionally, ATS numbers Material IDs/Side Sets as:\n",
    "\n",
    "* 0-9 : reserved for boundaries, surface/bottom, etc\n",
    "* 10-99 : Land Cover side sets, typically NLCD IDs are used\n",
    "* 100-999 : geologic layer material IDs. 999 is reserved for bedrock.\n",
    "* 1000-9999 : soil layer material IDs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map SSURGO mukey to ATS_ID\n",
    "soil_survey_props_clean['ats_id'] = range(1000, 1000+len(soil_survey_props_clean))\n",
    "soil_survey_props_clean.set_index('ats_id', inplace=True)\n",
    "\n",
    "# map GLHYMPS id to ATS_ID\n",
    "geo_survey_props_clean['ats_id'] = range(100, 100+len(geo_survey_props_clean))\n",
    "geo_survey_props_clean.set_index('ats_id', inplace=True)\n",
    "\n",
    "bedrock_props = watershed_workflow.soil_properties.get_bedrock_properties()\n",
    "\n",
    "# merge the properties databases\n",
    "subsurface_props = pandas.concat([geo_survey_props_clean,\n",
    "                                  soil_survey_props_clean,\n",
    "                                  bedrock_props])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesh extrusion\n",
    "\n",
    "Given the surface mesh and material IDs on both the surface and subsurface, we can extrude the surface mesh in the vertical to make a 3D mesh.\n",
    "\n",
    "Next we extrude the DEM to create a 3D mesh.\n",
    "\n",
    "The most difficult aspect of extrusion is creating meshes that:\n",
    "1. aren't huge numbers of cells\n",
    "2. aren't huge cell thicknesses, especially near the surface\n",
    "3. follow implied interfaces, e.g. bottom of soil and bottom of geologic layer\n",
    "\n",
    "This is an iterative process that requires some care and some art."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we choose the bottom of the domain to be the maximum of the depth to bedrock.\n",
    "# This is really up to the user, but we are hard-coding this for this watershed_workflow.\n",
    "dtb_max = np.nanmax(DTB)\n",
    "DTB = np.where(np.isnan(DTB), dtb_max, DTB)\n",
    "\n",
    "total_thickness = np.ceil(DTB.max())\n",
    "print(f'total thickness: {total_thickness} m')\n",
    "\n",
    "total_thickness = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dz structure for the top 2m of soil\n",
    "# here we try for 10 cells, starting at 5cm at the top and going to 50cm at the bottom of the 2m thick soil\n",
    "dzs, res = watershed_workflow.mesh.optimize_dzs(0.05, 0.5, 2, 10)\n",
    "print(dzs)\n",
    "print(sum(dzs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this looks like it would work out, with rounder numbers:\n",
    "dzs_soil = [0.05, 0.05, 0.05, 0.12, 0.23, 0.5, 0.5, 0.5]\n",
    "print(sum(dzs_soil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 m total thickness, minus 2m soil thickness, leaves us with 28 meters to make up.\n",
    "# optimize again...\n",
    "dzs2, res2 = watershed_workflow.mesh.optimize_dzs(1, 10, 28, 6)\n",
    "print(dzs2)\n",
    "print(sum(dzs2))\n",
    "\n",
    "# how about...\n",
    "dzs_geo = [1, 2,3] + 2*[6,]\n",
    "print(dzs_geo)\n",
    "print(sum(dzs_geo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soil structure\n",
    "use_geologic_layer = True\n",
    "\n",
    "# layer extrusion\n",
    "# -- data structures needed for extrusion\n",
    "layer_types = []\n",
    "layer_data = []\n",
    "layer_ncells = []\n",
    "layer_mat_ids = []\n",
    "\n",
    "# -- soil layer --\n",
    "depth = 0\n",
    "for dz in dzs_soil:\n",
    "    depth += 0.5 * dz\n",
    "    layer_types.append('constant')\n",
    "    layer_data.append(dz)\n",
    "    layer_ncells.append(1)\n",
    "\n",
    "    if use_geologic_layer:\n",
    "        # use glhymps params\n",
    "        br_or_geo = np.where(depth < DTB, geo_color_new, 999)\n",
    "        soil_or_br_or_geo = np.where(np.bitwise_and(soil_color_new > 0, depth < soil_thickness),\n",
    "                                 soil_color_new,\n",
    "                                 br_or_geo)\n",
    "    else:\n",
    "        # use ssurgo down to DTB if it exists\n",
    "        soil_or_geo = np.where(soil_color_new > 0, soil_color_new, geo_color_new)\n",
    "        soil_or_br_or_geo = np.where(depth < DTB, soil_or_geo, 999)\n",
    "    layer_mat_ids.append(soil_or_br_or_geo)\n",
    "    depth += 0.5 * dz\n",
    "\n",
    "# -- geologic layer --\n",
    "for dz in dzs_geo:\n",
    "    depth += 0.5 * dz\n",
    "    layer_types.append('constant')\n",
    "    layer_data.append(dz)\n",
    "    layer_ncells.append(1)\n",
    "\n",
    "    if use_geologic_layer:\n",
    "        geo_or_br = np.where(depth < DTB, geo_color_new, 999)\n",
    "    else:\n",
    "        # only soil, no geo\n",
    "        soil_or_geo = np.where(soil_color_new > 0, soil_color_new, geo_color_new)\n",
    "        geo_or_br = np.where(depth < DTB, soil_or_geo, 999)\n",
    "\n",
    "    layer_mat_ids.append(geo_or_br)\n",
    "    depth += 0.5 * dz\n",
    "\n",
    "# print the summary\n",
    "watershed_workflow.mesh.Mesh3D.summarize_extrusion(layer_types, layer_data,\n",
    "                                            layer_ncells, layer_mat_ids)\n",
    "\n",
    "# downselect subsurface properties to only those that are used\n",
    "layer_mat_id_used = list(np.unique(np.array(layer_mat_ids)))\n",
    "subsurface_props_used = subsurface_props.loc[layer_mat_id_used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrude\n",
    "m3 = watershed_workflow.mesh.Mesh3D.extruded_Mesh2D(m2, layer_types, layer_data,\n",
    "                                             layer_ncells, layer_mat_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk\n",
    "filename = os.path.join('../'+name+'_data' , 'output_data', 'coweeta_basin')\n",
    "\n",
    "if watershed_workflow.mesh.exodus is not None:\n",
    "    try:\n",
    "        os.remove(filename+'.exo')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    m3.write_exodus(filename+'.exo')\n",
    "\n",
    "else:\n",
    "    try:\n",
    "        os.remove(filename+'.vtk')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    m3.write_vtk(filename+'.vtk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (watershed_workflow)",
   "language": "python",
   "name": "watershed_workflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
